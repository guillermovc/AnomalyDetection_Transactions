{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-23T06:15:02.972564Z","iopub.execute_input":"2021-11-23T06:15:02.973259Z","iopub.status.idle":"2021-11-23T06:15:03.008772Z","shell.execute_reply.started":"2021-11-23T06:15:02.973126Z","shell.execute_reply":"2021-11-23T06:15:03.007587Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Introducción\n\n### Contexto\nEs importante para las compañias el poder detectar transacciones bancarias fraudulentas para que así sus clientes no tengan cargos por productos que no han comprado.\n\n### El set de datos\nEl conjunto de datos contiene transacciones hechas por tarjetas de crédito en septiembre de 2013 por tarjetahabientes de Europa.\n\n### Un problema común\nEn total, el set de datos contiene 284,807 transacciones, pero de estas, solo 492 son fraudulentas, es decir, el set está increiblemente desbalanceado. Por lo que al utilizar modelos de aprendizaje máquina habituales, corremos el riesgo de que este no logre aprender y generalizar las características fundamentales de cada clase para diferenciar entre transacciones reales y fraudulentas.\n\n### Acerca de las columnas\nLas columnas contienen solamente datos numéricos, obtenidos a traves de una transformacion PCA (Principal Component Analysis ó Análisis de Componentes Principales). Desafortunadamente, debido a que las características originales revelan información privada de los clientes, no podemos conocerlas con exactitud.\nLas caracteristicas V1, V2, ... V28 son los componentes principales obtenidos con PCA. Las columnas 'Tiempo' y 'Monto' son las únicas que no han sido transformadas. 'Tiempo' contiene los segundos tomados entre cada transacción y la primera transacción del set de datos. 'Monto' es el monto de la transacción. La característica 'Clase' toma el valor 1 en caso de fraude y 0 en otro caso.\n\n### Qué esperar en esta libreta\n- Métodos para balancear los datos.\n- Comparación entre distintos métodos tradicionales de aprendizaje máquina.\n- Una aproximación al problema utilizando autoencoders.\n\n### Créditos\n#### Dataset\nhttps://www.kaggle.com/mlg-ulb/creditcardfraud\n#### Ideas\nAlgunas ideas fueron tomadas de los siguientes enlaces\n- [Este video](https://www.youtube.com/watch?v=NCgjcHLFNDg)\n- [Esta libreta](https://www.kaggle.com/robinteuwens/anomaly-detection-with-auto-encoders)\n\nLibreta realizada originalmente en [kaggle](kaggle.com) por Guillermo Velazquez","metadata":{}},{"cell_type":"markdown","source":"# Importando las librerías necesarias","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\n\n# Visualización\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# random\nimport random","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:15:03.010963Z","iopub.execute_input":"2021-11-23T06:15:03.011493Z","iopub.status.idle":"2021-11-23T06:15:09.124010Z","shell.execute_reply.started":"2021-11-23T06:15:03.011447Z","shell.execute_reply":"2021-11-23T06:15:09.123259Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# cargar el set de datos\ndata_path = '../input/creditcardfraud/creditcard.csv' # La ruta al set de datos en el la libreta de kaggle\ndf = pd.read_csv(data_path)\n\n# Semillas aleatorias para garantizar la reproducibilidad de los datos\nSEMILLA_ALEATORIA = 11  # Puede ser cualquier número\nMUESTRA_ENTRENAMIENTO = 200000 # El número de muestras que tomaremos para entrenar\n\nnp.random.seed(SEMILLA_ALEATORIA)\nrandom.seed(SEMILLA_ALEATORIA)\ntf.random.set_seed(SEMILLA_ALEATORIA)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:15:09.125341Z","iopub.execute_input":"2021-11-23T06:15:09.125675Z","iopub.status.idle":"2021-11-23T06:15:13.189193Z","shell.execute_reply.started":"2021-11-23T06:15:09.125634Z","shell.execute_reply":"2021-11-23T06:15:13.188113Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"## Renombrando las columnas\nLos nombres de las columnas están en inglés e inician con mayusculas. Asi que vamos a convertirlas para evitar errores de mano y para que todo esté en español.","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:15:13.190954Z","iopub.execute_input":"2021-11-23T06:15:13.191175Z","iopub.status.idle":"2021-11-23T06:15:13.230766Z","shell.execute_reply.started":"2021-11-23T06:15:13.191149Z","shell.execute_reply":"2021-11-23T06:15:13.229776Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"df.columns = map(str.lower, df.columns)\ndf.rename(columns={'time':'tiempo', 'amount':'monto', 'class':'fraude'}, inplace=True)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:15:13.232004Z","iopub.execute_input":"2021-11-23T06:15:13.232228Z","iopub.status.idle":"2021-11-23T06:15:13.265439Z","shell.execute_reply.started":"2021-11-23T06:15:13.232203Z","shell.execute_reply":"2021-11-23T06:15:13.264662Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Explorando los datos","metadata":{}},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:15:13.266725Z","iopub.execute_input":"2021-11-23T06:15:13.267243Z","iopub.status.idle":"2021-11-23T06:15:13.312122Z","shell.execute_reply.started":"2021-11-23T06:15:13.267207Z","shell.execute_reply":"2021-11-23T06:15:13.311184Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### Valores faltantes","metadata":{}},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:15:13.313667Z","iopub.execute_input":"2021-11-23T06:15:13.313882Z","iopub.status.idle":"2021-11-23T06:15:13.341565Z","shell.execute_reply.started":"2021-11-23T06:15:13.313856Z","shell.execute_reply":"2021-11-23T06:15:13.340686Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"Como podemos ver, no tenemos ningún valor faltante, lo que es bueno.","metadata":{}},{"cell_type":"markdown","source":"### Distribución de las clases (0 real, 1 fraude)","metadata":{}},{"cell_type":"code","source":"print(df['fraude'].value_counts())\nprint(max(df['fraude'].value_counts().array) / (df['fraude'].count()))\ndf['fraude'].value_counts().plot(kind='bar')","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:15:13.342911Z","iopub.execute_input":"2021-11-23T06:15:13.343117Z","iopub.status.idle":"2021-11-23T06:15:13.555164Z","shell.execute_reply.started":"2021-11-23T06:15:13.343092Z","shell.execute_reply":"2021-11-23T06:15:13.554209Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"Observemos que, como se mencionó en la introducción, tenemos un set de datos muy desbalanceado. Más del 99% de los datos pertenece a la clase 'real'.","metadata":{}},{"cell_type":"markdown","source":"## Tomando una muestra de transacciones legítimas del mismo tamaño que el de fraudulentas.","metadata":{}},{"cell_type":"code","source":"cantidad_fraudulentos = df.loc[df['fraude'] == 1].shape[0]\n\n# Creando un dataframe separado con sólo transacciones reales\nreales = df[ df['fraude'] == 0 ]\nfalsos = df[ df['fraude'] == 1 ]\n\n# Tomando la muestra\nmuestra_reales = reales.sample(n = cantidad_fraudulentos)\n\n# Uniendo las muestras\ndf_balanceado = pd.concat([falsos, muestra_reales], axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:15:13.557752Z","iopub.execute_input":"2021-11-23T06:15:13.557996Z","iopub.status.idle":"2021-11-23T06:15:13.614688Z","shell.execute_reply.started":"2021-11-23T06:15:13.557969Z","shell.execute_reply":"2021-11-23T06:15:13.613829Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df_balanceado.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:15:13.615985Z","iopub.execute_input":"2021-11-23T06:15:13.616292Z","iopub.status.idle":"2021-11-23T06:15:13.645710Z","shell.execute_reply.started":"2021-11-23T06:15:13.616252Z","shell.execute_reply":"2021-11-23T06:15:13.644862Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"df_balanceado.tail()","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:15:13.646991Z","iopub.execute_input":"2021-11-23T06:15:13.647429Z","iopub.status.idle":"2021-11-23T06:15:13.674577Z","shell.execute_reply.started":"2021-11-23T06:15:13.647381Z","shell.execute_reply":"2021-11-23T06:15:13.673981Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"df_balanceado['fraude'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:15:13.675923Z","iopub.execute_input":"2021-11-23T06:15:13.676344Z","iopub.status.idle":"2021-11-23T06:15:13.683198Z","shell.execute_reply.started":"2021-11-23T06:15:13.676313Z","shell.execute_reply":"2021-11-23T06:15:13.682464Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"Como ven, ahora tenemos un set de datos balanceado","metadata":{}},{"cell_type":"markdown","source":"## Separando las características de la variable objetivo","metadata":{}},{"cell_type":"code","source":"X = df_balanceado.drop(columns='fraude', axis = 1) # Dropeamos la columna fraude y nos quedamos sólo con las características\ny = df_balanceado['fraude']  # Tomamos la columna de 'fraude' como nuestra variable objetivo","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:15:13.684582Z","iopub.execute_input":"2021-11-23T06:15:13.685037Z","iopub.status.idle":"2021-11-23T06:15:13.698668Z","shell.execute_reply.started":"2021-11-23T06:15:13.685006Z","shell.execute_reply":"2021-11-23T06:15:13.697868Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"print(X)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:15:13.700165Z","iopub.execute_input":"2021-11-23T06:15:13.700457Z","iopub.status.idle":"2021-11-23T06:15:13.729076Z","shell.execute_reply.started":"2021-11-23T06:15:13.700425Z","shell.execute_reply":"2021-11-23T06:15:13.728219Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"print(y)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:15:13.730609Z","iopub.execute_input":"2021-11-23T06:15:13.731112Z","iopub.status.idle":"2021-11-23T06:15:13.742962Z","shell.execute_reply.started":"2021-11-23T06:15:13.731070Z","shell.execute_reply":"2021-11-23T06:15:13.742077Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Dividir los datos en subconjuntos de prueba y entrenamiento","metadata":{}},{"cell_type":"code","source":"# importamos las librerias necesarias\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:15:13.744697Z","iopub.execute_input":"2021-11-23T06:15:13.745193Z","iopub.status.idle":"2021-11-23T06:15:13.929483Z","shell.execute_reply.started":"2021-11-23T06:15:13.745150Z","shell.execute_reply":"2021-11-23T06:15:13.928451Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# 80% para entrenamiento y 20% para prueba\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=SEMILLA_ALEATORIA)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:43:24.336677Z","iopub.execute_input":"2021-11-23T06:43:24.337413Z","iopub.status.idle":"2021-11-23T06:43:24.354071Z","shell.execute_reply.started":"2021-11-23T06:43:24.337321Z","shell.execute_reply":"2021-11-23T06:43:24.353098Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"print(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:15:13.942679Z","iopub.execute_input":"2021-11-23T06:15:13.943412Z","iopub.status.idle":"2021-11-23T06:15:13.952147Z","shell.execute_reply.started":"2021-11-23T06:15:13.943356Z","shell.execute_reply":"2021-11-23T06:15:13.951462Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"# Entrenando modelos","metadata":{}},{"cell_type":"markdown","source":"## Regresión Logística","metadata":{}},{"cell_type":"code","source":"# Librerias necesarias para el modelo y para medir la precisión\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:15:13.953423Z","iopub.execute_input":"2021-11-23T06:15:13.953794Z","iopub.status.idle":"2021-11-23T06:15:14.048085Z","shell.execute_reply.started":"2021-11-23T06:15:13.953754Z","shell.execute_reply":"2021-11-23T06:15:14.047455Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# Creamos nuestro modeo\nmodelo_rl = LogisticRegression(solver='liblinear')","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:15:14.049143Z","iopub.execute_input":"2021-11-23T06:15:14.049543Z","iopub.status.idle":"2021-11-23T06:15:14.053380Z","shell.execute_reply.started":"2021-11-23T06:15:14.049507Z","shell.execute_reply":"2021-11-23T06:15:14.052673Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Entrenando el modelo de regresión logística con los datos de entrenamiento\nmodelo_rl.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:15:14.054755Z","iopub.execute_input":"2021-11-23T06:15:14.055189Z","iopub.status.idle":"2021-11-23T06:15:14.083273Z","shell.execute_reply.started":"2021-11-23T06:15:14.055158Z","shell.execute_reply":"2021-11-23T06:15:14.082483Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"### Evaluando el modelo\n#### Accuracy score para las muestras con las que fue entrenado","metadata":{}},{"cell_type":"code","source":"y_pred_train = modelo_rl.predict(X_train)\nprecision_rl_train = accuracy_score(y_train, y_pred_train)\n\n# Imprimimos la precisión de entrenamiento\nprint('Precisión del modelo para el set de entrenamiento:', precision_rl_train)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:15:14.084411Z","iopub.execute_input":"2021-11-23T06:15:14.084942Z","iopub.status.idle":"2021-11-23T06:15:14.093880Z","shell.execute_reply.started":"2021-11-23T06:15:14.084903Z","shell.execute_reply":"2021-11-23T06:15:14.092928Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"#### Accuracy score para las muestras de prueba","metadata":{}},{"cell_type":"code","source":"y_pred_test = modelo_rl.predict(X_test)\nprecision_rl_test = accuracy_score(y_test, y_pred_test)\n\n# Imprimimos la precisión de prueba\nprint('Precision del modelo para el set de prueba:', precision_rl_test)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:15:14.095653Z","iopub.execute_input":"2021-11-23T06:15:14.096295Z","iopub.status.idle":"2021-11-23T06:15:14.107156Z","shell.execute_reply.started":"2021-11-23T06:15:14.096251Z","shell.execute_reply":"2021-11-23T06:15:14.106225Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"#### Resultados del modelo de Regresión Logística\nObtuvimos una precisión del 92.88% para el set de entrenameinto.  \nObtuvimos una precisión el 95.93% para el set de prueba.  \nPodemos decir que el modelo generalizó bastante bien utilizando solamente menos de 500 muestras de cada clase.","metadata":{}},{"cell_type":"markdown","source":"## Modelos basados en árboles","metadata":{}},{"cell_type":"markdown","source":"### Bosques aleatorios (random forest)","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n\nmodelo_rf = RandomForestClassifier(max_depth=8, random_state=SEMILLA_ALEATORIA)\nmodelo_rf.fit(X_train, y_train)\n\nmodelo_rf_pred = modelo_rf.predict(X_test)\nprecision_rf = accuracy_score(y_test, modelo_rf_pred)\n\nprint('Precision del modelo de bosques aleatorios:', precision_rf)\n# Matrix de confusion\nprint(confusion_matrix(y_test, modelo_rf_pred))","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:52:16.513540Z","iopub.execute_input":"2021-11-23T06:52:16.513839Z","iopub.status.idle":"2021-11-23T06:52:16.892380Z","shell.execute_reply.started":"2021-11-23T06:52:16.513803Z","shell.execute_reply":"2021-11-23T06:52:16.891268Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"#### Resultados del modelo de bosque aleatorio\nHasta ahora, hemos obtenido la precisión más alta con bosque aleatorio, que fue de un 97.4%\nY como podemos observar en la matriz de confusión, tenemos una buena separación de los tipos de datos.","metadata":{}},{"cell_type":"markdown","source":"### Bosque de aislamiento (isolation forest)","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import IsolationForest\n\nmodelo_if = IsolationForest(random_state=SEMILLA_ALEATORIA)\nmodelo_if.fit(X_train, y_train)\n\nmodelo_if_pred = modelo_if.predict(X_test)\nprecision_if = accuracy_score(y_test, modelo_if_pred)\n\nprint('Precision del modelo de bosque de aislamiento:', precision_if)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:56:50.060214Z","iopub.execute_input":"2021-11-23T06:56:50.060581Z","iopub.status.idle":"2021-11-23T06:56:50.343688Z","shell.execute_reply.started":"2021-11-23T06:56:50.060544Z","shell.execute_reply":"2021-11-23T06:56:50.342725Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"#### Resultados de bosques de aislamiento\nNos arrojaron una precision del 32%, lo que es bastante malo.","metadata":{}},{"cell_type":"markdown","source":"## Un acercamiento con autoencoders\n### ¿Qué es un autoencoder?\nUn autoencoder no es más que otra arquitectura de red neuronal que, en cierta fase de la misma comprime la información recibida a una versión muy reducida, denominado espacio latente. Al proceso de comprimir la información de una entrada al espacio latente, se le llama reducción de la dimensionalidad.  \nLa entrada y la salida de un autoencoder son la misma. ¿Por qué? porque queremos que nuestra red neuronal aprenda a reconstruir, con error mínimo, los datos que le son dados.    \n\n**¿De qué sirve obtener como salida lo que alimento como entrada?**  \nA simple vista, se puede creer que este resultado es poco útil, pero no es así, pues, al comparar los datos de entrada y los de salida podemos calcular un **error**, es decir, que tanto difiere la entrada de la salida.  \nEsto nos sirve para aprovechar sets de datos muy debalanceados, pues la estrategia es entrenar al autoencoder para que aprenda a reconstruir entradas de una sola clase (de la que tengamos más muestras) con un error muy bajo. Con esto, cuando la entrada sea un dato anómalo, el error deberá ser mayor al error promedio que tendría reconstruyendo un dato normal.  \nEs importante establecer un threshold adecuado para poder distinguir cuándo un error de reconstrucción dictará que el dato de entrada se trata de una anomalía.  \n  \nIntentemos utilizar un autoencoder para detectar cuando una transacción es fraudulenta.","metadata":{}},{"cell_type":"markdown","source":"### Normalizando los datos de la columna monto\nPara normalizar los datos utilizaremos una distribución normal logarítmica equivalente.","metadata":{}},{"cell_type":"code","source":"# Añadimos una cantidad insignificante para evitar tomar el logaritmo de 0\ndf['log10_monto'] = np.log10(df.monto + 0.00001)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:15:14.762671Z","iopub.execute_input":"2021-11-23T06:15:14.763515Z","iopub.status.idle":"2021-11-23T06:15:14.782700Z","shell.execute_reply.started":"2021-11-23T06:15:14.763468Z","shell.execute_reply":"2021-11-23T06:15:14.781760Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:15:14.784181Z","iopub.execute_input":"2021-11-23T06:15:14.785175Z","iopub.status.idle":"2021-11-23T06:15:14.809085Z","shell.execute_reply.started":"2021-11-23T06:15:14.785138Z","shell.execute_reply":"2021-11-23T06:15:14.808430Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"RATIO_FRAUDE = 15\n\ndf2 = df.copy().drop(['tiempo', 'monto'], axis=1)\n\n# Dividir por clase\nfraude = df2[df2.fraude == 1]\nreal   = df2[df2.fraude == 0]\n\n# Tomamos una muestra de las transacciones reales\nmuestra_reales = real.sample(int(len(fraude) * RATIO_FRAUDE), random_state=SEMILLA_ALEATORIA)\n\n# Concatenamos los nuevos dataframes en uno solo\nvisualizacion = pd.concat([fraude, muestra_reales])\nnombres_columnas = list(visualizacion.drop('fraude', axis=1).columns)\n\n# Aislar las características de las etiquetas\ncaract, etiquetas = visualizacion.drop('fraude', axis=1).values , visualizacion.fraude.values","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:15:14.810093Z","iopub.execute_input":"2021-11-23T06:15:14.810862Z","iopub.status.idle":"2021-11-23T06:15:14.996325Z","shell.execute_reply.started":"2021-11-23T06:15:14.810829Z","shell.execute_reply":"2021-11-23T06:15:14.995537Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"print(f\"\"\"The non-fraud dataset has been undersampled from {len(real):,} to {len(muestra_reales):,}.\nThis represents a ratio of {RATIO_FRAUDE}:1 to fraud.\"\"\")","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:15:14.997285Z","iopub.execute_input":"2021-11-23T06:15:14.997959Z","iopub.status.idle":"2021-11-23T06:15:15.002984Z","shell.execute_reply.started":"2021-11-23T06:15:14.997918Z","shell.execute_reply":"2021-11-23T06:15:15.002125Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"### t-SNE","metadata":{}},{"cell_type":"code","source":"from sklearn.manifold import TSNE\nfrom mpl_toolkits.mplot3d import Axes3D\n\ndef tsne_scatter(features, labels, dimensions=2, save_as='graph.png'):\n    if dimensions not in (2, 3):\n        raise ValueError('tsne_scatter can only plot in 2d or 3d (What are you? An alien that can visualise >3d?). Make sure the \"dimensions\" argument is in (2, 3)')\n\n    # t-SNE dimensionality reduction\n    features_embedded = TSNE(n_components=dimensions, random_state=SEMILLA_ALEATORIA).fit_transform(features)\n    \n    # initialising the plot\n    fig, ax = plt.subplots(figsize=(8,8))\n    \n    # counting dimensions\n    if dimensions == 3: ax = fig.add_subplot(111, projection='3d')\n\n    # plotting data\n    ax.scatter(\n        *zip(*features_embedded[np.where(labels==1)]),\n        marker='o',\n        color='r',\n        s=2,\n        alpha=0.7,\n        label='Fraude'\n    )\n    ax.scatter(\n        *zip(*features_embedded[np.where(labels==0)]),\n        marker='o',\n        color='g',\n        s=2,\n        alpha=0.3,\n        label='Real'\n    )\n\n    # storing it to be displayed later\n    plt.legend(loc='best')\n    plt.savefig(save_as);\n    plt.show;","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:15:15.004753Z","iopub.execute_input":"2021-11-23T06:15:15.005254Z","iopub.status.idle":"2021-11-23T06:15:15.044995Z","shell.execute_reply.started":"2021-11-23T06:15:15.005211Z","shell.execute_reply":"2021-11-23T06:15:15.044012Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"tsne_scatter(caract, etiquetas, dimensions=2, save_as='tsne_initial_2d.png')","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:15:15.046191Z","iopub.execute_input":"2021-11-23T06:15:15.046458Z","iopub.status.idle":"2021-11-23T06:16:04.918778Z","shell.execute_reply.started":"2021-11-23T06:15:15.046424Z","shell.execute_reply":"2021-11-23T06:16:04.917901Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"### Separando en set de entrenamiento y prueba\nComo mencionamos antes, los autoencoders solo se entrenan utilizando muestras de una clase. En este caso, entrenaremos al nuestro con las muestras de la clase de transacciones reales.","metadata":{}},{"cell_type":"code","source":"# Revolver el set de entrenamiento\nreal = real.sample(frac=1).reset_index(drop=True)\n\n# Set de entrenamiento, solo transacciones no fraudulentas\nX_train = real.iloc[:MUESTRA_ENTRENAMIENTO].drop('fraude', axis=1)\n\n# Set de prueba, las muestras no fraudulentas que restan y todas las fraudulentas\nX_test = real.iloc[MUESTRA_ENTRENAMIENTO:].append(fraude).sample(frac=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:16:04.920008Z","iopub.execute_input":"2021-11-23T06:16:04.920341Z","iopub.status.idle":"2021-11-23T06:16:05.158888Z","shell.execute_reply.started":"2021-11-23T06:16:04.920307Z","shell.execute_reply":"2021-11-23T06:16:05.158175Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# Dividiendo el entrenamiento y la validación\nX_train, X_validate = train_test_split(X_train, test_size=0.2, random_state=SEMILLA_ALEATORIA)\n\n# Manualmente dividiendo las etiquetas del dataframe de prueba\nX_test, y_test = X_test.drop('fraude', axis=1).values, X_test.fraude.values","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:16:05.160142Z","iopub.execute_input":"2021-11-23T06:16:05.160564Z","iopub.status.idle":"2021-11-23T06:16:05.254708Z","shell.execute_reply.started":"2021-11-23T06:16:05.160529Z","shell.execute_reply":"2021-11-23T06:16:05.253999Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"### Normalizando los datos y creando un Pipeline\nNormalizar ayuda al modelo a converger más rápido","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import Normalizer, MinMaxScaler\nfrom sklearn.pipeline import Pipeline\n\n# Configurar el Pipeline\npipeline = Pipeline([('normalizer', Normalizer()), ('scaler', MinMaxScaler())])","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:16:05.255936Z","iopub.execute_input":"2021-11-23T06:16:05.256353Z","iopub.status.idle":"2021-11-23T06:16:05.264499Z","shell.execute_reply.started":"2021-11-23T06:16:05.256313Z","shell.execute_reply":"2021-11-23T06:16:05.263584Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"#### Entrenando el pipeline","metadata":{}},{"cell_type":"code","source":"pipeline.fit(X_train)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:16:05.269048Z","iopub.execute_input":"2021-11-23T06:16:05.271457Z","iopub.status.idle":"2021-11-23T06:16:05.347401Z","shell.execute_reply.started":"2021-11-23T06:16:05.271404Z","shell.execute_reply":"2021-11-23T06:16:05.346683Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"#### Aplicamos transformaciones con los parámetros adquiridos","metadata":{}},{"cell_type":"code","source":"X_train_transformed = pipeline.transform(X_train)\nX_validate_transformed = pipeline.transform(X_validate)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:16:05.351524Z","iopub.execute_input":"2021-11-23T06:16:05.353470Z","iopub.status.idle":"2021-11-23T06:16:05.428993Z","shell.execute_reply.started":"2021-11-23T06:16:05.353423Z","shell.execute_reply":"2021-11-23T06:16:05.427958Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"### Entrenando el Autoencoder","metadata":{}},{"cell_type":"code","source":"# Importando librerias necesarias\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n# Declaramos las constantes\ntam_entrada = X_train_transformed.shape[1]\nBATCH_SIZE = 256\nEPOCHS = 100\n\n# Creamos nuestra red neuronal\nautoencoder = Sequential()\nautoencoder.add( Dense(tam_entrada, activation='elu', input_shape=(tam_entrada,)) )\nautoencoder.add( Dense(16, activation='elu') )\nautoencoder.add( Dense(8, activation='elu') )\nautoencoder.add( Dense(4, activation='elu') )\nautoencoder.add( Dense(2, activation='elu') )\n\n# Reconstrucción / decode\nautoencoder.add( Dense(4, activation='elu') )\nautoencoder.add( Dense(8, activation='elu') )\nautoencoder.add( Dense(16, activation='elu') )\nautoencoder.add( Dense(tam_entrada, activation='elu') )\n\nautoencoder.compile(optimizer='adam', loss='mse', metrics=['acc'])\n\nautoencoder.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:16:05.430414Z","iopub.execute_input":"2021-11-23T06:16:05.430734Z","iopub.status.idle":"2021-11-23T06:16:06.717087Z","shell.execute_reply.started":"2021-11-23T06:16:05.430691Z","shell.execute_reply":"2021-11-23T06:16:06.716204Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"# EarlyStopping nos permite entrenar con muchos epochs y parar cuando nuestro modelo deje de aprender\nearly_stopping = EarlyStopping(\n    monitor='val_loss',\n    min_delta=0.0001,\n    patience=10,\n    verbose=1,\n    mode='min',\n    restore_best_weights=True\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:16:06.718346Z","iopub.execute_input":"2021-11-23T06:16:06.718619Z","iopub.status.idle":"2021-11-23T06:16:06.723204Z","shell.execute_reply.started":"2021-11-23T06:16:06.718589Z","shell.execute_reply":"2021-11-23T06:16:06.722176Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"markdown","source":"### Entrenamiento","metadata":{}},{"cell_type":"code","source":"history = autoencoder.fit(X_train_transformed, X_train_transformed, \n                          shuffle=True, epochs=EPOCHS, batch_size=BATCH_SIZE, \n                          callbacks=[early_stopping],\n                          validation_data=(X_validate_transformed, X_validate_transformed))","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:16:06.724747Z","iopub.execute_input":"2021-11-23T06:16:06.725032Z","iopub.status.idle":"2021-11-23T06:20:56.116166Z","shell.execute_reply.started":"2021-11-23T06:16:06.724995Z","shell.execute_reply":"2021-11-23T06:20:56.114949Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":"### Reconstrucciones","metadata":{}},{"cell_type":"code","source":"# Transformamos el set de prueba con los parámetros del pipeline\nX_test_transformed = pipeline.transform(X_test)\n\n# Pasamos los datos transformados a través del autoencoder para obtener el resultado de la reconstrucción\nreconstrucciones = autoencoder.predict(X_test_transformed)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:20:56.117953Z","iopub.execute_input":"2021-11-23T06:20:56.118375Z","iopub.status.idle":"2021-11-23T06:21:01.444370Z","shell.execute_reply.started":"2021-11-23T06:20:56.118314Z","shell.execute_reply":"2021-11-23T06:21:01.443349Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"markdown","source":"### Calculando la perdida de reconstrucción para cada transacción","metadata":{}},{"cell_type":"code","source":"# Calculando el error cuadrado medio de la reconstruccion\nmse = np.mean(np.power(X_test_transformed - reconstrucciones, 2), axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:21:01.446078Z","iopub.execute_input":"2021-11-23T06:21:01.446451Z","iopub.status.idle":"2021-11-23T06:21:01.497708Z","shell.execute_reply.started":"2021-11-23T06:21:01.446403Z","shell.execute_reply":"2021-11-23T06:21:01.496655Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"fraude = mse[y_test == 0]\nreal   = mse[y_test == 1]\n\nfig, ax = plt.subplots(figsize=(6,6))\n\nax.hist(real, bins=50, density=True, label='reales', alpha=0.6, color='green')\nax.hist(fraude, bins=50, density=True, label='fraudes', alpha=0.6, color='red')\n\nplt.title('Distribución (normalizada) de la perdida de reconstrucción')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:21:01.499052Z","iopub.execute_input":"2021-11-23T06:21:01.499407Z","iopub.status.idle":"2021-11-23T06:21:01.941821Z","shell.execute_reply.started":"2021-11-23T06:21:01.499341Z","shell.execute_reply":"2021-11-23T06:21:01.940708Z"},"trusted":true},"execution_count":41,"outputs":[]},{"cell_type":"markdown","source":"Se ve que podríamos separar muchas transacciones fraudulentas de las reales, aunque algunas pasan por alto.","metadata":{}},{"cell_type":"markdown","source":"### Estableciendo un Threshold para clasificación","metadata":{}},{"cell_type":"code","source":"THRESHOLD = 3\n\ndef mad_score(points):\n    m = np.median(points)\n    ad = np.abs(points - m)\n    mad = np.median(ad)\n    \n    return 0.6745 * ad / mad\n\nz_scores = mad_score(mse)\noutliers = z_scores > THRESHOLD","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:23:54.891123Z","iopub.execute_input":"2021-11-23T06:23:54.891449Z","iopub.status.idle":"2021-11-23T06:23:54.901601Z","shell.execute_reply.started":"2021-11-23T06:23:54.891417Z","shell.execute_reply":"2021-11-23T06:23:54.900602Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"markdown","source":"### Creando una matriz de confusión","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, precision_recall_curve\n\ncm = confusion_matrix(y_test, outliers)\n(tn, fp, fn, tp) = cm.flatten()","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:28:55.633971Z","iopub.execute_input":"2021-11-23T06:28:55.634263Z","iopub.status.idle":"2021-11-23T06:28:55.996225Z","shell.execute_reply.started":"2021-11-23T06:28:55.634234Z","shell.execute_reply":"2021-11-23T06:28:55.995142Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"print(f\"\"\"La clasificación usando el metodo MAD con un threshold de ={THRESHOLD} son los siguientes:\n{cm}\n\n% de transacciones etiquetadas como fraude que fueron correctas (precisión): {tp}/({fp}+{tp}) = {tp/(fp+tp):.2%}\n% de transacciones fraudulentas fueron detectadas satisfactoriamente (recall):    {tp}/({fn}+{tp}) = {tp/(fn+tp):.2%}\"\"\")","metadata":{"execution":{"iopub.status.busy":"2021-11-23T06:28:56.831824Z","iopub.execute_input":"2021-11-23T06:28:56.832157Z","iopub.status.idle":"2021-11-23T06:28:56.838827Z","shell.execute_reply.started":"2021-11-23T06:28:56.832124Z","shell.execute_reply":"2021-11-23T06:28:56.837907Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"## Conclusión\nEl autoencoder no fue capaz de generalizar por completo. Sin embargo, tengamos en cuenta que este fue entrenado solo con una clase de transacciones, lo que es muy beneficioso para nosotros cuando tengamos un número muy mínimo de muestras de cierta clase.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}